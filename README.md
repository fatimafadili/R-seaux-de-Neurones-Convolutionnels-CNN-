Convolutional Neural Networks (CNNs) - Projet √âducatif
https://img.shields.io/badge/TensorFlow-2.x-orange
https://img.shields.io/badge/Python-3.8+-blue
https://img.shields.io/badge/Jupyter-Notebook-red
https://img.shields.io/badge/License-MIT-green

üìã Table des Mati√®res
Introduction

Structure du Projet

Installation

Contenu D√©taill√©

Applications Pratiques

R√©sultats

Utilisation

Contribuer

Licence

üéØ Introduction
Ce projet √©ducatif pr√©sente une introduction compl√®te aux R√©seaux de Neurones Convolutionnels (CNN) √† travers des explications th√©oriques et des impl√©mentations pratiques. Le notebook guide les √©tudiants depuis les concepts fondamentaux jusqu'aux applications avanc√©es de la vision par ordinateur.

Objectifs P√©dagogiques
‚úÖ Comprendre les principes de base des convolutions

‚úÖ Ma√Ætriser les architectures CNN standards

‚úÖ Appliquer les CNN √† des t√¢ches r√©elles

‚úÖ Explorer la segmentation et d√©tection d'objets

‚úÖ Comparer diff√©rentes architectures de r√©seaux

üèóÔ∏è Structure du Projet
text
CNN_24_25_Version_Etu.ipynb/
‚îÇ
‚îú‚îÄ‚îÄ 1Ô∏è‚É£ INTRODUCTION AUX CNN
‚îÇ   ‚îú‚îÄ‚îÄ 1.1 Pourquoi les CNN ?
‚îÇ   ‚îú‚îÄ‚îÄ 1.2 Principe de base des convolutions
‚îÇ   ‚îî‚îÄ‚îÄ 1.3 Exemple simple avec TensorFlow
‚îÇ
‚îú‚îÄ‚îÄ 2Ô∏è‚É£ APPLICATIONS PRATIQUES
‚îÇ   ‚îú‚îÄ‚îÄ 2.1 Convolution avec plusieurs filtres
‚îÇ   ‚îú‚îÄ‚îÄ 2.2 Fonctions d'activation (ReLU)
‚îÇ   ‚îú‚îÄ‚îÄ 2.3 Couches de Pooling
‚îÇ   ‚îî‚îÄ‚îÄ 2.4 Architecture compl√®te
‚îÇ
‚îú‚îÄ‚îÄ 3Ô∏è‚É£ CLASSIFICATION D'IMAGES
‚îÇ   ‚îú‚îÄ‚îÄ 3.1 MNIST - Chiffres manuscrits
‚îÇ   ‚îú‚îÄ‚îÄ 3.2 CIFAR-10 - Objets divers
‚îÇ   ‚îî‚îÄ‚îÄ 3.3 Comparaison ANN vs CNN
‚îÇ
‚îú‚îÄ‚îÄ 4Ô∏è‚É£ SEGMENTATION D'IMAGES
‚îÇ   ‚îú‚îÄ‚îÄ 4.1 M√©thodes traditionnelles
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Seuillage (Thresholding)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ K-means clustering
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ D√©tection de contours
‚îÇ   ‚îú‚îÄ‚îÄ 4.2 Segmentation avec CNN
‚îÇ   ‚îî‚îÄ‚îÄ 4.3 U-Net sur Oxford-IIIT Pets
‚îÇ
‚îú‚îÄ‚îÄ 5Ô∏è‚É£ D√âTECTION D'OBJETS
‚îÇ   ‚îú‚îÄ‚îÄ 5.1 SSD (Single Shot Detector)
‚îÇ   ‚îú‚îÄ‚îÄ 5.2 PASCAL VOC 2007
‚îÇ   ‚îú‚îÄ‚îÄ 5.3 M√©triques d'√©valuation (IoU)
‚îÇ   ‚îî‚îÄ‚îÄ 5.4 Mod√®les avanc√©s (YOLO/Detectron2)
‚îÇ
‚îî‚îÄ‚îÄ 6Ô∏è‚É£ EXERCICES ET PROJETS
    ‚îú‚îÄ‚îÄ Exercice 1h : Consolidation des concepts
    ‚îî‚îÄ‚îÄ Mini-projet 1 semaine : D√©tection avanc√©e
‚öôÔ∏è Installation
Pr√©requis
Python 3.8 ou sup√©rieur

Jupyter Notebook ou Google Colab

8 Go de RAM minimum (recommand√©)

GPU (optionnel mais recommand√© pour l'entra√Ænement)

Installation des D√©pendances
bash
# Cloner le repository
git clone https://github.com/votre-username/cnn-educational-project.git
cd cnn-educational-project

# Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les d√©pendances
pip install -r requirements.txt
requirements.txt :

text
tensorflow>=2.8.0
numpy>=1.21.0
matplotlib>=3.5.0
opencv-python>=4.5.0
pillow>=9.0.0
scikit-learn>=1.0.0
pandas>=1.3.0
tensorflow-datasets>=4.5.0
üìö Contenu D√©taill√©
Partie 1 : Fondamentaux des CNN
1.1 Convolution Simple
python
# Exemple de convolution avec TensorFlow
import tensorflow as tf
import numpy as np

# Image 5x5 et filtre 3x3
image = np.array([[1,2,3,4,5], ...])
kernel = np.array([[-1,-1,-1], [0,0,0], [1,1,1]])

# Application de la convolution
convolved = tf.nn.conv2d(image_tf, kernel_tf, strides=[1,1,1,1], padding='VALID')
1.2 Filtres Multiples
Filtre Horizontal : D√©tection des bords horizontaux

Filtre Vertical : D√©tection des bords verticaux

Filtre Sobel : D√©tection am√©lior√©e des contours

Filtre Laplacien : D√©tection des changements brusques

Filtre Flou : Lissage d'image

Filtre Sharpening : Renforcement des d√©tails

Partie 2 : Architectures CNN
2.1 Bloc CNN Standard
python
model = tf.keras.Sequential([
    # Couche Convolutionnelle
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),
    
    # Pooling
    tf.keras.layers.MaxPooling2D((2,2)),
    
    # Couches suppl√©mentaires
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2,2)),
    
    # Classification
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])
2.2 Am√©liorations Avanc√©es
Batch Normalization : Stabilisation de l'entra√Ænement

Dropout : R√©duction du surapprentissage

Data Augmentation : Augmentation artificielle des donn√©es

Learning Rate Scheduling : Ajustement dynamique du taux d'apprentissage

üöÄ Applications Pratiques
Application 1 : Classification MNIST
Objectif : Reconna√Ætre les chiffres manuscrits
Architecture : CNN simple
Performance : ~99% de pr√©cision
Temps d'entra√Ænement : 5 minutes sur CPU

Application 2 : Classification CIFAR-10
Objectif : Classifier 10 cat√©gories d'objets
Architecture : CNN am√©lior√© avec Dropout
Performance : ~75% de pr√©cision
Temps d'entra√Ænement : 30 minutes sur GPU

Application 3 : Segmentation Oxford-IIIT Pets
Objectif : Segmenter les chats et chiens
Architecture : U-Net
Performance : IoU > 0.7
Temps d'entra√Ænement : 2 heures sur GPU

Application 4 : D√©tection PASCAL VOC
Objectif : D√©tecter 20 classes d'objets
Architecture : SSD avec MobileNetV2
Performance : IoU variable selon la classe
Temps d'entra√Ænement : 1 heure sur GPU

üìä R√©sultats
Comparaison des Performances
Mod√®le	Dataset	Pr√©cision	IoU	Temps d'entra√Ænement
ANN Simple	MNIST	97%	-	2 min
CNN Simple	MNIST	99%	-	5 min
CNN Am√©lior√©	CIFAR-10	75%	-	30 min
U-Net	Oxford Pets	-	0.72	2 h
SSD	PASCAL VOC	-	0.45-0.70	1 h
Visualisations
Filtres Appris : Visualisation des patterns appris

Feature Maps : Activation des diff√©rentes couches

Courbes d'Apprentissage : Suivi de la perte et pr√©cision

Pr√©dictions : Comparaison avec les v√©ritables labels

üéÆ Utilisation
Ex√©cution Compl√®te
bash
# Ouvrir le notebook
jupyter notebook CNN_24_25_Version_Etu.ipynb

# Ou utiliser Google Colab
# T√©l√©charger le notebook et l'ouvrir dans Colab
Ex√©cution Section par Section
Section 1 : Concepts fondamentaux (30 min)

Section 2 : Applications de base (45 min)

Section 3 : Classification (1 h)

Section 4 : Segmentation (1.5 h)

Section 5 : D√©tection d'objets (2 h)

Section 6 : Projets pratiques (variable)

Pour les Enseignants
python
# Configuration recommand√©e pour la classe
config = {
    "sections_par_cours": 2,
    "dur√©e_totale": "6 s√©ances de 3h",
    "pr√©requis": "Python, Alg√®bre lin√©aire",
    "mat√©riel": "Colab Pro recommand√©",
    "√©valuation": "Projet final + exercices"
}
ü§ù Contribuer
Les contributions sont les bienvenues ! Voici comment contribuer :

Fork le projet

Clone votre fork

Cr√©ez une branche pour votre fonctionnalit√©

Commitez vos changements

Push vers votre branche

Cr√©ez une Pull Request

Guide de Style
Code comment√© en fran√ßais ou anglais

Documentation claire et compl√®te

Tests pour les nouvelles fonctionnalit√©s

Respect des conventions PEP 8

üìÑ Licence
Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de d√©tails.

text
MIT License

Copyright (c) 2024 [fatima el fadili]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:
...
üë• Auteurs
Votre Nom - D√©veloppement initial - votre-email@domaine.com

Contributeurs - Voir la liste des contributeurs

üôè Remerciements
TensorFlow Team pour l'excellente documentation

Google Colab pour les ressources de calcul

Communaut√© Open Source pour les datasets et outils

√âtudiants pour les retours et am√©liorations

üìö R√©f√©rences
Deep Learning - Ian Goodfellow

TensorFlow Documentation

CS231n - Stanford University

Papers with Code
